[![license](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](./LICENSE)

## ECG classification using MIT-BIH dataset 

This repo is an implementation of https://www.nature.com/articles/s41591-018-0268-3 and https://arxiv.org/abs/1707.01836

and focus on training using a MIT-BIH dataset. If you want to train using CINC or open irhythm data, see the open source which the authors of the original research paper have coded at https://github.com/awni/ecg

Introduction to MIT-BIH dataset at physionet : https://physionet.org/physiobank/database/mitdb/

### Dependency 

Consistent with the environment of Google colab with wfdb, deepdish installations and numpy reinstallation. 

- Python >= 3.6.7
- keras==2.2.5
- tensorflow==1.15.0 
- scikit-learn==0.21.3
- wfdb==2.2.1
- deepdish==0.3.6
- scipy==1.3.1
- numpy==1.15.4
- tqdm==4.36.1
- six==1.12.0
- Flask==1.1.1
- gevent==1.4.0
- werkzeug==0.16.0
- virtualenv==16.7.7




### Data setup and train 

I recommend using a vitual enviroment for Python, so run setup.sh in order to install and to activate it. 
```
$ git clone https://github.com/physhik/ecg-mit-bih.git
$ cd ecg-mit-bih
$ sh setup sh.
```
Now you have a trained model for ECG classification 


### Test

Predict an annotation of [CINC2017 data](https://physionet.org/challenge/2017/) or your own data(csv file)

It randomly chooses one of data, and predict the slices of the signal.

Run predict.py in the virtual environment we have already set up.
```
(flaskapp) $ ./flaskapp/bin/python predict.py --cinc_download True
```
--cinc_download branch is used at first to download the CINC2017 data.

See config.py and customize your parameters or learn better way to train and test 


### Jupyter notebook example

In case, you do not have a GPU above a decent performance, you might be able to use Google colab. Follow the [Jupyter notebook](https://github.com/physhik/ecg-mit-bih/blob/master/src/practice/ecg_mit.ipynb).


### Flask web app

The flask web app is based on the 500 stared [Github repo](https://github.com/mtobeiyf/keras-flask-deploy-webapp). 

#### Run app.py
```
(flaskapp) $ ./flaskapp/bin/python app.py
```

![png](src/static/asset/capture1.png)

and choose a csv heart heat signal and click predict, and see the result. 

![png](src/static/asset/capture2.png)

I have put one csv file in static/asset directory. The first value of the column become sample rate of the web app. If you use your own heart beat csv file, insert the sample at the first, too.   


### Using Docker, Buld and run an image for the ECG trained model.

After installation of Docker, 

```
$ docker build -t ecg-app .  
$ docker run -d -p 5000:5000 ecg-app
```

### Pull an built-image from Docker hub

Or for your convenience, pull the image from Docker hub by 

```
$ docker pull physhik/ecg-app:1 
$ docker run -d -p 5000:5000 physhik/ecg-app:1
```

and then open http://localhost:5000 after a while installing the app in the container. 



### Introduction to ECG 

I presented a bit more about ECG classfications on my personal blog, http://physhik.com 

Find the posts from tags or categories easily.  

### Reference to 

The original research papers
https://www.nature.com/articles/s41591-018-0268-3
https://arxiv.org/abs/1707.01836

The open source by authors
https://github.com/awni/ecg

also noticable 
https://github.com/fernandoandreotti/cinc-challenge2017/tree/master/deeplearn-approach

## Note

The code in tf 1.X might work well, but in tf 2.0, it will raise None value not support error. It might happen in the optimter part. Some value will be none in the process.
To solve this problem, we can use `from tensorflow.keras.optimizers import Adam` instead of `from keras.optimizers import Adam`, but the opt in tf not support lr reduce, so ReduceLROnPlateau in the callback is not supported. or it will raise lr not found error. we can comment this just to see some result.


# My note

## Model
```

Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input (InputLayer)              (None, 256, 1)       0
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 256, 32)      544         input[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 256, 32)      128         conv1d_1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256, 32)      0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 256, 32)      16416       activation_1[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 256, 32)      128         conv1d_2[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 256, 32)      0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256, 32)      0           activation_2[0][0]
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 256, 32)      0           activation_1[0][0]
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 256, 32)      16416       dropout_1[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 256, 32)      0           max_pooling1d_1[0][0]
                                                                 conv1d_3[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 256, 32)      128         add_1[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 256, 32)      0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 128, 32)      16416       activation_3[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 128, 32)      128         conv1d_4[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 128, 32)      0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 128, 32)      0           activation_4[0][0]
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 128, 32)      0           add_1[0][0]
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 128, 32)      16416       dropout_2[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 128, 32)      0           max_pooling1d_2[0][0]
                                                                 conv1d_5[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 128, 32)      128         add_2[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 128, 32)      0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 128, 32)      16416       activation_5[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 128, 32)      128         conv1d_6[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 128, 32)      0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 128, 32)      0           activation_6[0][0]
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 128, 32)      0           add_2[0][0]
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 128, 32)      16416       dropout_3[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 128, 32)      0           max_pooling1d_3[0][0]
                                                                 conv1d_7[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 128, 32)      128         add_3[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 128, 32)      0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 64, 32)       16416       activation_7[0][0]
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 64, 32)       128         conv1d_8[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 64, 32)       0           batch_normalization_8[0][0]
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 64, 32)       0           activation_8[0][0]
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 64, 32)       0           add_3[0][0]
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 64, 32)       16416       dropout_4[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 64, 32)       0           max_pooling1d_4[0][0]
                                                                 conv1d_9[0][0]
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 64, 32)       128         add_4[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 64, 32)       0           batch_normalization_9[0][0]
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 64, 32)       16416       activation_9[0][0]
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 64, 32)       128         conv1d_10[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 64, 32)       0           batch_normalization_10[0][0]
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 64, 32)       0           activation_10[0][0]
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 64, 32)       0           add_4[0][0]
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, 64, 32)       16416       dropout_5[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 64, 32)       0           max_pooling1d_5[0][0]
                                                                 conv1d_11[0][0]
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 64, 32)       128         add_5[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 64, 32)       0           batch_normalization_11[0][0]
__________________________________________________________________________________________________
conv1d_12 (Conv1D)              (None, 32, 64)       32832       activation_11[0][0]
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 64)       256         conv1d_12[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 64)       0           batch_normalization_12[0][0]
__________________________________________________________________________________________________
max_pooling1d_6 (MaxPooling1D)  (None, 32, 32)       0           add_5[0][0]
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 32, 64)       0           activation_12[0][0]
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 32, 64)       0           max_pooling1d_6[0][0]
__________________________________________________________________________________________________
conv1d_13 (Conv1D)              (None, 32, 64)       65600       dropout_6[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 64)       0           lambda_1[0][0]
                                                                 conv1d_13[0][0]
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 64)       256         add_6[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 64)       0           batch_normalization_13[0][0]
__________________________________________________________________________________________________
conv1d_14 (Conv1D)              (None, 32, 64)       65600       activation_13[0][0]
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 64)       256         conv1d_14[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 64)       0           batch_normalization_14[0][0]
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 32, 64)       0           activation_14[0][0]
__________________________________________________________________________________________________
max_pooling1d_7 (MaxPooling1D)  (None, 32, 64)       0           add_6[0][0]
__________________________________________________________________________________________________
conv1d_15 (Conv1D)              (None, 32, 64)       65600       dropout_7[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 64)       0           max_pooling1d_7[0][0]
                                                                 conv1d_15[0][0]
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 64)       256         add_7[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 64)       0           batch_normalization_15[0][0]
__________________________________________________________________________________________________
conv1d_16 (Conv1D)              (None, 16, 64)       65600       activation_15[0][0]
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 64)       256         conv1d_16[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 64)       0           batch_normalization_16[0][0]
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 64)       0           activation_16[0][0]
__________________________________________________________________________________________________
max_pooling1d_8 (MaxPooling1D)  (None, 16, 64)       0           add_7[0][0]
__________________________________________________________________________________________________
conv1d_17 (Conv1D)              (None, 16, 64)       65600       dropout_8[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 64)       0           max_pooling1d_8[0][0]
                                                                 conv1d_17[0][0]
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 64)       256         add_8[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 64)       0           batch_normalization_17[0][0]
__________________________________________________________________________________________________
conv1d_18 (Conv1D)              (None, 16, 64)       65600       activation_17[0][0]
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 16, 64)       256         conv1d_18[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 16, 64)       0           batch_normalization_18[0][0]
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 16, 64)       0           activation_18[0][0]
__________________________________________________________________________________________________
max_pooling1d_9 (MaxPooling1D)  (None, 16, 64)       0           add_8[0][0]
__________________________________________________________________________________________________
conv1d_19 (Conv1D)              (None, 16, 64)       65600       dropout_9[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 64)       0           max_pooling1d_9[0][0]
                                                                 conv1d_19[0][0]
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 16, 64)       256         add_9[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 16, 64)       0           batch_normalization_19[0][0]
__________________________________________________________________________________________________
conv1d_20 (Conv1D)              (None, 8, 128)       131200      activation_19[0][0]
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 128)       512         conv1d_20[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 128)       0           batch_normalization_20[0][0]
__________________________________________________________________________________________________
max_pooling1d_10 (MaxPooling1D) (None, 8, 64)        0           add_9[0][0]
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 128)       0           activation_20[0][0]
__________________________________________________________________________________________________
lambda_2 (Lambda)               (None, 8, 128)       0           max_pooling1d_10[0][0]
__________________________________________________________________________________________________
conv1d_21 (Conv1D)              (None, 8, 128)       262272      dropout_10[0][0]
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 128)       0           lambda_2[0][0]
                                                                 conv1d_21[0][0]
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 128)       512         add_10[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 128)       0           batch_normalization_21[0][0]
__________________________________________________________________________________________________
conv1d_22 (Conv1D)              (None, 8, 128)       262272      activation_21[0][0]
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 128)       512         conv1d_22[0][0]
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 128)       0           batch_normalization_22[0][0]
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 128)       0           activation_22[0][0]
__________________________________________________________________________________________________
max_pooling1d_11 (MaxPooling1D) (None, 8, 128)       0           add_10[0][0]
__________________________________________________________________________________________________
conv1d_23 (Conv1D)              (None, 8, 128)       262272      dropout_11[0][0]
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 128)       0           max_pooling1d_11[0][0]
                                                                 conv1d_23[0][0]
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 128)       512         add_11[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 128)       0           batch_normalization_23[0][0]
__________________________________________________________________________________________________
conv1d_24 (Conv1D)              (None, 4, 128)       262272      activation_23[0][0]
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 4, 128)       512         conv1d_24[0][0]
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 4, 128)       0           batch_normalization_24[0][0]
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 4, 128)       0           activation_24[0][0]
__________________________________________________________________________________________________
max_pooling1d_12 (MaxPooling1D) (None, 4, 128)       0           add_11[0][0]
__________________________________________________________________________________________________
conv1d_25 (Conv1D)              (None, 4, 128)       262272      dropout_12[0][0]
__________________________________________________________________________________________________
add_12 (Add)                    (None, 4, 128)       0           max_pooling1d_12[0][0]
                                                                 conv1d_25[0][0]
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 4, 128)       512         add_12[0][0]
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 4, 128)       0           batch_normalization_25[0][0]
__________________________________________________________________________________________________
conv1d_26 (Conv1D)              (None, 4, 128)       262272      activation_25[0][0]
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 4, 128)       512         conv1d_26[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 4, 128)       0           batch_normalization_26[0][0]
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 4, 128)       0           activation_26[0][0]
__________________________________________________________________________________________________
max_pooling1d_13 (MaxPooling1D) (None, 4, 128)       0           add_12[0][0]
__________________________________________________________________________________________________
conv1d_27 (Conv1D)              (None, 4, 128)       262272      dropout_13[0][0]
__________________________________________________________________________________________________
add_13 (Add)                    (None, 4, 128)       0           max_pooling1d_13[0][0]
                                                                 conv1d_27[0][0]
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 4, 128)       512         add_13[0][0]
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 4, 128)       0           batch_normalization_27[0][0]
__________________________________________________________________________________________________
conv1d_28 (Conv1D)              (None, 2, 256)       524544      activation_27[0][0]
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 2, 256)       1024        conv1d_28[0][0]
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 2, 256)       0           batch_normalization_28[0][0]
__________________________________________________________________________________________________
max_pooling1d_14 (MaxPooling1D) (None, 2, 128)       0           add_13[0][0]
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 2, 256)       0           activation_28[0][0]
__________________________________________________________________________________________________
lambda_3 (Lambda)               (None, 2, 256)       0           max_pooling1d_14[0][0]
__________________________________________________________________________________________________
conv1d_29 (Conv1D)              (None, 2, 256)       1048832     dropout_14[0][0]
__________________________________________________________________________________________________
add_14 (Add)                    (None, 2, 256)       0           lambda_3[0][0]
                                                                 conv1d_29[0][0]
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 2, 256)       1024        add_14[0][0]
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 2, 256)       0           batch_normalization_29[0][0]
__________________________________________________________________________________________________
conv1d_30 (Conv1D)              (None, 2, 256)       1048832     activation_29[0][0]
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 2, 256)       1024        conv1d_30[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 2, 256)       0           batch_normalization_30[0][0]
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 2, 256)       0           activation_30[0][0]
__________________________________________________________________________________________________
max_pooling1d_15 (MaxPooling1D) (None, 2, 256)       0           add_14[0][0]
__________________________________________________________________________________________________
conv1d_31 (Conv1D)              (None, 2, 256)       1048832     dropout_15[0][0]
__________________________________________________________________________________________________
add_15 (Add)                    (None, 2, 256)       0           max_pooling1d_15[0][0]
                                                                 conv1d_31[0][0]
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 2, 256)       1024        add_15[0][0]
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 2, 256)       0           batch_normalization_31[0][0]
__________________________________________________________________________________________________
conv1d_32 (Conv1D)              (None, 1, 256)       1048832     activation_31[0][0]
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 1, 256)       1024        conv1d_32[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 1, 256)       0           batch_normalization_32[0][0]
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 1, 256)       0           activation_32[0][0]
__________________________________________________________________________________________________
max_pooling1d_16 (MaxPooling1D) (None, 1, 256)       0           add_15[0][0]
__________________________________________________________________________________________________
conv1d_33 (Conv1D)              (None, 1, 256)       1048832     dropout_16[0][0]
__________________________________________________________________________________________________
add_16 (Add)                    (None, 1, 256)       0           max_pooling1d_16[0][0]
                                                                 conv1d_33[0][0]
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 1, 256)       1024        add_16[0][0]
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 1, 256)       0           batch_normalization_33[0][0]
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 1, 6)         1542        activation_33[0][0]
==================================================================================================
Total params: 8,407,782
Trainable params: 8,400,934
Non-trainable params: 6,848
```
   
